algo: "PPO"

env:
  n_envs: 128
  frame_stack: 5

train:
  total_timesteps: 1_000_000_0
  log_dir: "./tensor_logs"

model:
  policy: "CnnPolicy"
  features_dim: 512

  learning_rate: 0.0003 
  n_steps: 128
  batch_size: 4096
  n_epochs: 4
  gamma: 0.99
  gae_lambda: 0.95
  clip_range: 0.2
  ent_coef: 0.02
  vf_coef: 0.5
  max_grad_norm: 0.5
  
  verbose: 1
  device: "cuda"